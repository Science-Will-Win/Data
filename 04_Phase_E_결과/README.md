# 04_Phase_E_결과

같은 11개 문제를 3개 모델이 각각 풀고 비교하는 실험입니다.

## 3개 조건

| 조건 | 모델 | 설명 |
|------|------|------|
| 조건1: `base_r0` | Biomni-R0-32B-AWQ | 원본 바이오메디컬 전문 에이전트 |
| 조건2: `gdpo` | Qwen3-32B + GDPO | 선호도 학습만 적용 |
| 조건3: `gdpo_unc` | 조건2 + 불확실성 프롬프트 | "확신 없으면 거부" 지시 추가 |

## 결과 요약

| 조건 | 성공 | 성공률 | 평균시간 |
|------|------|--------|---------|
| Base R0 | 3/11 | **27.3%** | 340.5초 |
| GDPO | 0/11 | 0% | 479.4초 |
| GDPO+불확실성 | 2/11 | 18.2% | 233.9초 |

## 태스크별 결과

| 태스크 | Base R0 | GDPO | GDPO+Unc |
|--------|---------|------|----------|
| gwas_variant_134 | ✅ | ❌ | ❌ |
| seqqa_533 | ✅ | ❌ | ✅ |
| screen_gene_190 | ❌ | ❌ | ❌ |
| CloningScenarios_32 | ❌ | ❌ | ❌ |
| DbQA_73 | ❌ | ❌ | ❌ |
| FigQA_36 | ❌ | ❌ | ❌ |
| LitQA2_21 | ❌ | ❌ | ❌ |
| ProtocolQA_24 | ❌ | ❌ | ❌ |
| SeqQA_521 | ❌ | ❌ | ❌ |
| SuppQA_57 | ❌ | ❌ | ✅ |
| TableQA_25 | ✅ | ❌ | ❌ |

## 핵심 교훈

1. **Base R0 > GDPO**: 도구 전문성이 선호도 학습보다 중요
2. **불확실성 프롬프트 효과**: GDPO(0%) → GDPO+Unc(18.2%)
3. **GDPO는 R0 위에 적용해야**: 범용 모델에 적용하메 도구 호출 불가
